{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a384f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48a7a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'style',\n",
      "       'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote',\n",
      "       'image', 'reviewLength', 'reviewAge'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from preprocessor import Preprocessor\n",
    "import scipy.sparse as sp\n",
    "# Define the path to your data file\n",
    "# data_file_path = \"C:\\\\Users\\\\Saad\\\\Desktop\\\\Study\\\\Saad Learnings\\\\Python\\\\School Python\\\\Intro to AI Assignments\\\\Assignments\\\\Project\\\\Software_5-core.json\"\n",
    "data_file_path = \"C:\\\\Users\\\\sa909892\\\\Learnings\\\\a_Learnings\\\\New folder\\\\Project\\\\Software_5-core.json\"\n",
    "\n",
    "\n",
    "reviews = pd.read_json(data_file_path, lines = True) #Convert the list of dictionaries into a pandas DataFrame\n",
    "reviews = Preprocessor.clean_review_objects(reviews)# Read data from the JSON file into a list of dictionaries\n",
    "print(reviews.columns)\n",
    "reviews[\"cleanedTokens\"] = reviews[\"reviewText\"].apply(Preprocessor.clean_text).apply(Preprocessor.stem_words)\n",
    "reviews[\"cleanedReview\"] = reviews[\"cleanedTokens\"].apply(lambda tokens: \" \".join(tokens))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(reviews)\n",
    "# what I need in the data: \"overall\": 5.0 (stars), \"vote\": \"3\" (helpful button), \"verified\": false (real person)\n",
    "#print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c2801be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall            int64\n",
      "verified           int32\n",
      "reviewTime        object\n",
      "reviewerID        object\n",
      "asin              object\n",
      "style             object\n",
      "reviewerName      object\n",
      "reviewText        object\n",
      "summary           object\n",
      "unixReviewTime     int64\n",
      "vote              object\n",
      "image             object\n",
      "reviewLength       int64\n",
      "reviewAge          int64\n",
      "cleanedTokens     object\n",
      "cleanedReview     object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_corrected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m string_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_converted\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munixReviewTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewLength\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewAge\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert desired columns to strings\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df_converted[string_cols] \u001b[38;5;241m=\u001b[39m df_corrected[string_cols]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure 'verified' is boolean\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df_converted[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_converted[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_corrected' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a copy to avoid modifying the original (optional)\n",
    "df_converted = df.copy()\n",
    "\n",
    "# Investigate data types\n",
    "print(df_converted.dtypes)\n",
    "\n",
    "# List of columns to potentially convert to strings (excluding 'asin', 'verified', 'vote', 'unixReviewTime', 'reviewLength', 'reviewAge')\n",
    "string_cols = [col for col in df_converted.columns if col not in ['asin', 'verified', 'vote', 'unixReviewTime', 'reviewLength', 'reviewAge']]\n",
    "\n",
    "\n",
    "df_converted[string_cols] = df_corrected[string_cols].astype(str)\n",
    "\n",
    "# Ensure 'verified' is boolean\n",
    "df_converted[\"verified\"] = df_converted[\"verified\"].astype(bool)\n",
    "\n",
    "# Handle 'vote' conversion if necessary (assuming it's numeric)\n",
    "if pd.api.types.is_numeric_dtype(df_converted[\"vote\"]):\n",
    "  df_converted[\"vote\"] = df_converted[\"vote\"].astype(str)  # Convert to string if numeric\n",
    "\n",
    "# Drop ignored columns (optional)\n",
    "# You can comment out this line if you want to keep these columns but not convert them to strings\n",
    "df_converted = df_converted.drop(columns=['unixReviewTime', 'reviewLength', 'reviewAge'])  \n",
    "\n",
    "print(df_converted.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "180a26f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall            int64\n",
      "verified            bool\n",
      "reviewTime        object\n",
      "reviewerID        object\n",
      "asin              object\n",
      "style             object\n",
      "reviewerName      object\n",
      "reviewText        object\n",
      "summary           object\n",
      "unixReviewTime     int64\n",
      "vote              object\n",
      "image             object\n",
      "reviewLength       int64\n",
      "reviewAge          int64\n",
      "cleanedTokens     object\n",
      "cleanedReview     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_verified = df[df['verified'] == True]\n",
    "\n",
    "#reviews[\"vote\"] = reviews[\"vote\"].astype(str)  # Convert to string for cleaning\n",
    "\n",
    "#reviews.loc[:, \"vote\"] = reviews[\"vote\"].fillna(0).astype(int)  # Convert back to integer\n",
    "\n",
    "\n",
    "df_verified[\"verified\"] = df_verified[\"verified\"].astype(bool) \n",
    "\n",
    "print(df_verified.dtypes)\n",
    "#processed_df = Preprocessor.clean_text(df_verified)\n",
    "df_verified = df[df['verified'] == True]\n",
    "\n",
    "#processed_df = Preprocessor.preprocess_reviews(df_verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a537de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2024-04-14 11:49:36 - preprocessor: Preprocessing data.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Filter out instances where \"verified\" is false\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#df_verified = df[df['verified'] == True]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Preprocess the reviews using the TextPreprocessor\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mpreprocess_reviews(df_verified)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Extract features and target variable\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(processed_df\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m~\\Learnings\\a_Learnings\\New folder\\Project\\preprocessor.py:55\u001b[0m, in \u001b[0;36mPreprocessor.preprocess_reviews\u001b[1;34m(reviews, lowercase_text, remove_punctuation, remove_stopwords, tokenization_strategy, text_normalization_strategy)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03mPreprocesses a DataFrame of reviews, performing various cleaning and normalization steps.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m:return: The input DataFrame with an additional 'cleanedReviewText' column containing the preprocessed text.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m reviews \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mclean_review_objects(reviews)\n\u001b[0;32m     56\u001b[0m reviews \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mstandardize_columns(reviews, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewLength\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewAge\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     57\u001b[0m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleanedReviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(Preprocessor\u001b[38;5;241m.\u001b[39mclean_text,\n\u001b[0;32m     58\u001b[0m                                                            lowercase_text\u001b[38;5;241m=\u001b[39mlowercase_text,\n\u001b[0;32m     59\u001b[0m                                                            remove_punctuation\u001b[38;5;241m=\u001b[39mremove_punctuation,\n\u001b[0;32m     60\u001b[0m                                                            remove_stopwords\u001b[38;5;241m=\u001b[39mremove_stopwords)\n",
      "File \u001b[1;32m~\\Learnings\\a_Learnings\\New folder\\Project\\preprocessor.py:138\u001b[0m, in \u001b[0;36mPreprocessor.clean_review_objects\u001b[1;34m(reviews, required_fields)\u001b[0m\n\u001b[0;32m    135\u001b[0m reviews \u001b[38;5;241m=\u001b[39m reviews\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39mrequired_fields, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    137\u001b[0m reviews\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 138\u001b[0m                           \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m                           \u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    140\u001b[0m                           \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[0;32m    141\u001b[0m reviews\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewLength\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen()\n\u001b[0;32m    143\u001b[0m reviews\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewTime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewTime\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Filter out instances where \"verified\" is false\n",
    "#df_verified = df[df['verified'] == True]\n",
    "\n",
    "\n",
    "# Preprocess the reviews using the TextPreprocessor\n",
    "processed_df = Preprocessor.preprocess_reviews(df_verified)\n",
    "\n",
    "# Extract features and target variable\n",
    "print(processed_df.columns)\n",
    "X_text = processed_df[\"reviewText\"].apply(Preprocessor.clean_text)\n",
    "X_features = processed_df[[\"overall\", \"verified\"]]\n",
    "y = df_vote[\"vote\"]\n",
    "\n",
    "print(X_text.shape)\n",
    "print(X_features.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_text_train, X_text_test, X_features_train, X_features_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ... rest of your code for model training and evaluation ...\n",
    "\n",
    "# Text feature extraction using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(X_text_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d795ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2024-04-12 18:29:20 - preprocessor: Preprocessing data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asin             \n",
      "B002DHGMK0  4197     [purchased, full, version, could, load, macboo...\n",
      "B00MHZ71G2  9641                                        [goo, product]\n",
      "B0000AZJY6  1966     [easy, install, xp, machine, drivers, worked, ...\n",
      "B00P6U8BA0  10421    [software, works, issues, wanting, post, somet...\n",
      "B009CCVMO0  7026     [worked, needed, thanks, last, years, version,...\n",
      "                                           ...                        \n",
      "B00FFINOWS  8658     [started, looking, tax, program, went, turbo, ...\n",
      "B005S4Y65I  6126                    [great, product, shipped, quickly]\n",
      "B005S4Y8TM  6245     [please, dont, accountant, irs, call, tax, sof...\n",
      "B009CCVMO0  7040     [wish, wouldnt, make, latest, software, versio...\n",
      "B0039L31JY  4636     [good, product, reasonable, price, fast, deliv...\n",
      "Name: reviewText, Length: 1908, dtype: object\n",
      "(478,)\n",
      "(1908, 2)\n",
      "(478, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Series.dropna() got an unexpected keyword argument 'subset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_features_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Preprocess the training and testing data\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m X_text_train_processed \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mpreprocess_reviews(X_text_train)\n\u001b[0;32m     15\u001b[0m X_text_test_processed \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mpreprocess_reviews(X_text_test)\n",
      "File \u001b[1;32m~\\Learnings\\a_Learnings\\New folder\\Project\\preprocessor.py:55\u001b[0m, in \u001b[0;36mPreprocessor.preprocess_reviews\u001b[1;34m(reviews, lowercase_text, remove_punctuation, remove_stopwords, tokenization_strategy, text_normalization_strategy)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03mPreprocesses a DataFrame of reviews, performing various cleaning and normalization steps.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m:return: The input DataFrame with an additional 'cleanedReviewText' column containing the preprocessed text.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m reviews \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mclean_review_objects(reviews)\n\u001b[0;32m     56\u001b[0m reviews \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mstandardize_columns(reviews, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewLength\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewAge\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     57\u001b[0m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleanedReviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(Preprocessor\u001b[38;5;241m.\u001b[39mclean_text,\n\u001b[0;32m     58\u001b[0m                                                            lowercase_text\u001b[38;5;241m=\u001b[39mlowercase_text,\n\u001b[0;32m     59\u001b[0m                                                            remove_punctuation\u001b[38;5;241m=\u001b[39mremove_punctuation,\n\u001b[0;32m     60\u001b[0m                                                            remove_stopwords\u001b[38;5;241m=\u001b[39mremove_stopwords)\n",
      "File \u001b[1;32m~\\Learnings\\a_Learnings\\New folder\\Project\\preprocessor.py:135\u001b[0m, in \u001b[0;36mPreprocessor.clean_review_objects\u001b[1;34m(reviews, required_fields)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_fields \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     required_fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 135\u001b[0m reviews \u001b[38;5;241m=\u001b[39m reviews\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39mrequired_fields, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    137\u001b[0m reviews\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (reviews[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    138\u001b[0m                           \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m                           \u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    140\u001b[0m                           \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Series.dropna() got an unexpected keyword argument 'subset'"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_text_train, X_text_test, X_features_train, X_features_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the text preprocessor\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "print(X_text_train)\n",
    "print(X_text_test.shape)\n",
    "print(X_features_train.shape)\n",
    "print(X_features_test.shape)\n",
    "\n",
    "# Preprocess the training and testing data\n",
    "X_text_train_processed = Preprocessor.preprocess_reviews(X_text_train)\n",
    "X_text_test_processed = Preprocessor.preprocess_reviews(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbcf8c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X_text_train, X_text_test, X_features_train, X_features_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m----> 3\u001b[0m     X_text, X_features, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize the text preprocessor\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#preprocessor = Preprocessor()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Preprocess the training and testing data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m X_text_train_processed \u001b[38;5;241m=\u001b[39m Preprocessor\u001b[38;5;241m.\u001b[39mpreprocess_reviews(X_text_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_text' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_text_train, X_text_test, X_features_train, X_features_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the text preprocessor\n",
    "#preprocessor = Preprocessor()\n",
    "\n",
    "# Preprocess the training and testing data\n",
    "X_text_train_processed = Preprocessor.preprocess_reviews(X_text_train)\n",
    "X_text_test_processed = Preprocessor.preprocess_reviews(X_text_test)\n",
    "\n",
    "# Convert text data into numerical features using TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_text_train_tfidf = tfidf_vectorizer.fit_transform(X_text_train_processed).Preprocessor.cleanedReviewText\n",
    "X_text_test_tfidf = tfidf_vectorizer.transform(X_text_test_processed['cleanedReviewText'])\n",
    "\n",
    "# Combine text features with other features\n",
    "X_train = sp.hstack((X_text_train_tfidf, X_features_train), format='csr')\n",
    "X_test = sp.hstack((X_text_test_tfidf, X_features_test), format='csr')\n",
    "\n",
    "# Initialize the SVR model for linear\n",
    "svr_model = SVR(kernel='linear')\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error of the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013c5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f22a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
